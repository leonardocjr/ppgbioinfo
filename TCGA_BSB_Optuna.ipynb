{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação e importação de Bibliotecas\n",
    "# pip install pandas numpy matplotlib scikit-learn optuna tensorflow keras\n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import optuna\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout, SpatialDropout1D, SimpleRNN, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento dos dados\n",
    "df = pd.read_csv(\"C:/Users/ana_v/OneDrive/Documentos/Mestrado/MachineLearning/TCGA.csv\", low_memory=False)\n",
    "unique_types = df['Type'].unique()\n",
    "type_to_numeric = {type_name: index for index, type_name in enumerate(unique_types)}\n",
    "df['Type'] = df['Type'].map(type_to_numeric)\n",
    "type_column = df['Type']\n",
    "df_num = df.drop(columns=[\"Sample\", \"Type\"])\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "dados_normalizados = scaler.fit_transform(df_num)\n",
    "\n",
    "# Aplicação do PCA\n",
    "pca = PCA(n_components=0.8)  \n",
    "pca.fit(dados_normalizados)\n",
    "dados_pca = pca.transform(dados_normalizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-22 16:51:34,667] A new study created in memory with name: no-name-1e761759-ba2a-4214-a303-6246e44637a6\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 16:51:43,635] Trial 0 finished with value: 0.743275167785235 and parameters: {'hidden_layer_sizes': (50, 25), 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.0002053104838395193, 'learning_rate_init': 0.0002831966545366896}. Best is trial 0 with value: 0.743275167785235.\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-22 16:51:45,823] Trial 1 finished with value: 0.7553020134228189 and parameters: {'hidden_layer_sizes': (50,), 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.0582191049554753, 'learning_rate_init': 0.005880474526406358}. Best is trial 1 with value: 0.7553020134228189.\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 16:52:02,881] Trial 2 finished with value: 0.7767337807606264 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'adam', 'alpha': 3.21052061691425e-05, 'learning_rate_init': 0.00029664239677389137}. Best is trial 2 with value: 0.7767337807606264.\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 16:52:09,870] Trial 3 finished with value: 0.6924653243847875 and parameters: {'hidden_layer_sizes': (50,), 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.0011012815249516852, 'learning_rate_init': 0.00022189660058905529}. Best is trial 2 with value: 0.7767337807606264.\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-22 16:52:16,337] Trial 4 finished with value: 0.7326174496644295 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.002125195637374944, 'learning_rate_init': 0.000436705636997169}. Best is trial 2 with value: 0.7767337807606264.\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-22 16:52:22,328] Trial 5 finished with value: 0.7807427293064877 and parameters: {'hidden_layer_sizes': (100, 50), 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.004037215302906866, 'learning_rate_init': 0.0035788920011262594}. Best is trial 5 with value: 0.7807427293064877.\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 16:52:37,437] Trial 6 finished with value: 0.8021565995525727 and parameters: {'hidden_layer_sizes': (50, 25), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.019463631700611245, 'learning_rate_init': 0.008053656710050518}. Best is trial 6 with value: 0.8021565995525727.\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-22 16:52:39,220] Trial 7 finished with value: 0.7512930648769575 and parameters: {'hidden_layer_sizes': (50,), 'activation': 'relu', 'solver': 'sgd', 'alpha': 7.122438156374793e-05, 'learning_rate_init': 0.00753476152346979}. Best is trial 6 with value: 0.8021565995525727.\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 16:52:48,306] Trial 8 finished with value: 0.7125906040268457 and parameters: {'hidden_layer_sizes': (100,), 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.019669587609644126, 'learning_rate_init': 0.0001188723550324684}. Best is trial 6 with value: 0.8021565995525727.\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\416433886.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-22 16:52:50,478] Trial 9 finished with value: 0.7753825503355705 and parameters: {'hidden_layer_sizes': (50,), 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0002460921717675059, 'learning_rate_init': 0.022708684929799543}. Best is trial 6 with value: 0.8021565995525727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para MLP: {'hidden_layer_sizes': (50, 25), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.019463631700611245, 'learning_rate_init': 0.008053656710050518}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Divisão de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(dados_pca, df['Type'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Função objetivo para otimização do MLP\n",
    "def objective_mlp(trial):\n",
    "    # Hiperparâmetros para MLP\n",
    "    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (100, 50), (50, 25)])\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'logistic'])\n",
    "    solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
    "    learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
    "    \n",
    "    # Criar e treinar o modelo\n",
    "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation,\n",
    "                          solver=solver, alpha=alpha, learning_rate_init=learning_rate_init,\n",
    "                          max_iter=500, random_state=42)\n",
    "    \n",
    "    # Validação cruzada\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Estudar otimização com Optuna para MLP\n",
    "study_mlp = optuna.create_study(direction='maximize')\n",
    "study_mlp.optimize(objective_mlp, n_trials=10)\n",
    "\n",
    "# Melhores parâmetros\n",
    "best_params_mlp = study_mlp.best_params\n",
    "print(\"Melhores parâmetros para MLP:\", best_params_mlp)\n",
    "\n",
    "# Treinamento e avaliação do MLP com melhores parâmetros\n",
    "best_mlp_model = MLPClassifier(hidden_layer_sizes=best_params_mlp['hidden_layer_sizes'],\n",
    "                               activation=best_params_mlp['activation'],\n",
    "                               solver=best_params_mlp['solver'],\n",
    "                               alpha=best_params_mlp['alpha'],\n",
    "                               learning_rate_init=best_params_mlp['learning_rate_init'],\n",
    "                               max_iter=500, random_state=42)\n",
    "best_mlp_model.fit(X_train, y_train)\n",
    "mlp_predictions_train = best_mlp_model.predict(X_train)\n",
    "mlp_predictions_test = best_mlp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados do MLP:\n",
      "Matriz de Confusão:\n",
      " [[76 14  1  4  2]\n",
      " [10 25  1  2  0]\n",
      " [ 1  1 26  0  1]\n",
      " [ 0  3  3  9  0]\n",
      " [ 5  0  1  0  2]]\n",
      "Acurácia (Treinamento): 0.9933155080213903\n",
      "Acurácia (Teste): 0.7379679144385026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média na validação cruzada (MLP): 0.7955\n",
      "\n",
      "Classification Report (MLP):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LumA       0.83      0.78      0.80        97\n",
      "        LumB       0.58      0.66      0.62        38\n",
      "       Basal       0.81      0.90      0.85        29\n",
      "        Her2       0.60      0.60      0.60        15\n",
      "      Normal       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.74       187\n",
      "   macro avg       0.64      0.64      0.64       187\n",
      "weighted avg       0.74      0.74      0.74       187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Avaliação para MLP\n",
    "print(\"\\nResultados do MLP:\")\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, mlp_predictions_test))\n",
    "print(\"Acurácia (Treinamento):\", accuracy_score(y_train, mlp_predictions_train))\n",
    "print(\"Acurácia (Teste):\", accuracy_score(y_test, mlp_predictions_test))\n",
    "\n",
    "# Acurácia média na validação cruzada\n",
    "cv_mean_score = cross_val_score(best_mlp_model, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "print(f'Acurácia média na validação cruzada (MLP): {cv_mean_score:.4f}')\n",
    "\n",
    "# Classification Report\n",
    "mlp_report = classification_report(y_test, mlp_predictions_test, zero_division=1, target_names=[str(cls) for cls in unique_types])\n",
    "print(f'\\nClassification Report (MLP):\\n{mlp_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-22 16:54:17,853] A new study created in memory with name: no-name-b4a8f953-8e41-48b2-9118-aded4f6bcd23\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_28808\\2000305426.py:28: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.5)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-08-22 16:54:26,810] Trial 0 finished with value: 0.8559194684028626 and parameters: {'filters': 57, 'kernel_size': 5, 'pool_size': 4, 'dense_units': 102, 'dropout_rate': 0.39419344373473975}. Best is trial 0 with value: 0.8559194684028626.\n",
      "[I 2024-08-22 16:54:35,740] Trial 1 finished with value: 0.9013333320617676 and parameters: {'filters': 52, 'kernel_size': 3, 'pool_size': 3, 'dense_units': 111, 'dropout_rate': 0.22879006961789408}. Best is trial 1 with value: 0.9013333320617676.\n",
      "[I 2024-08-22 16:54:48,055] Trial 2 finished with value: 0.9199731469154357 and parameters: {'filters': 64, 'kernel_size': 4, 'pool_size': 2, 'dense_units': 105, 'dropout_rate': 0.23479520196155776}. Best is trial 2 with value: 0.9199731469154357.\n",
      "[I 2024-08-22 16:54:54,594] Trial 3 finished with value: 0.8291812062263488 and parameters: {'filters': 37, 'kernel_size': 2, 'pool_size': 4, 'dense_units': 99, 'dropout_rate': 0.2893964487627092}. Best is trial 2 with value: 0.9199731469154357.\n",
      "[I 2024-08-22 16:55:01,541] Trial 4 finished with value: 0.870621919631958 and parameters: {'filters': 45, 'kernel_size': 3, 'pool_size': 4, 'dense_units': 120, 'dropout_rate': 0.28670104254994144}. Best is trial 2 with value: 0.9199731469154357.\n",
      "[I 2024-08-22 16:55:08,630] Trial 5 finished with value: 0.8532617568969727 and parameters: {'filters': 41, 'kernel_size': 2, 'pool_size': 3, 'dense_units': 70, 'dropout_rate': 0.23532005750089566}. Best is trial 2 with value: 0.9199731469154357.\n",
      "[I 2024-08-22 16:55:15,161] Trial 6 finished with value: 0.9066487669944763 and parameters: {'filters': 19, 'kernel_size': 5, 'pool_size': 2, 'dense_units': 73, 'dropout_rate': 0.4188080970889829}. Best is trial 2 with value: 0.9199731469154357.\n",
      "[I 2024-08-22 16:55:22,170] Trial 7 finished with value: 0.8812975406646728 and parameters: {'filters': 41, 'kernel_size': 5, 'pool_size': 4, 'dense_units': 102, 'dropout_rate': 0.3342174593730899}. Best is trial 2 with value: 0.9199731469154357.\n",
      "[I 2024-08-22 16:55:29,323] Trial 8 finished with value: 0.8972885966300964 and parameters: {'filters': 25, 'kernel_size': 3, 'pool_size': 2, 'dense_units': 96, 'dropout_rate': 0.28600952197275226}. Best is trial 2 with value: 0.9199731469154357.\n",
      "[I 2024-08-22 16:55:35,478] Trial 9 finished with value: 0.8438568234443664 and parameters: {'filters': 33, 'kernel_size': 3, 'pool_size': 4, 'dense_units': 70, 'dropout_rate': 0.40078174210803386}. Best is trial 2 with value: 0.9199731469154357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para CNN: {'filters': 64, 'kernel_size': 4, 'pool_size': 2, 'dense_units': 105, 'dropout_rate': 0.23479520196155776}\n",
      "Epoch 1/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.3782 - loss: 2.0233 - val_accuracy: 0.5882 - val_loss: 1.2307\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6626 - loss: 1.1116 - val_accuracy: 0.6524 - val_loss: 1.0106\n",
      "Epoch 3/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7455 - loss: 0.7337 - val_accuracy: 0.6952 - val_loss: 0.9197\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7642 - loss: 0.6200 - val_accuracy: 0.7059 - val_loss: 0.8399\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8387 - loss: 0.4665 - val_accuracy: 0.6524 - val_loss: 0.8580\n",
      "Epoch 6/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8904 - loss: 0.3633 - val_accuracy: 0.6738 - val_loss: 0.9850\n",
      "Epoch 7/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8995 - loss: 0.2903 - val_accuracy: 0.6684 - val_loss: 0.8643\n",
      "Epoch 8/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9183 - loss: 0.2107 - val_accuracy: 0.6738 - val_loss: 1.0599\n",
      "Epoch 9/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9328 - loss: 0.1810 - val_accuracy: 0.6578 - val_loss: 1.0702\n",
      "Epoch 10/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9626 - loss: 0.1419 - val_accuracy: 0.6578 - val_loss: 1.1016\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6736 - loss: 1.1466 \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "# Definir número de classes\n",
    "num_classes = len(unique_types) \n",
    "\n",
    "# Função para criar o modelo CNN\n",
    "def create_cnn_model(filters=32, kernel_size=3, pool_size=2, dense_units=64, dropout_rate=0.5):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=pool_size),\n",
    "        Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'),\n",
    "        MaxPooling1D(pool_size=pool_size),\n",
    "        Flatten(),\n",
    "        Dense(dense_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Função objetivo para otimização do CNN\n",
    "def objective_cnn(trial):\n",
    "    # Hiperparâmetros para CNN\n",
    "    filters = trial.suggest_int('filters', 16, 64)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 2, 5)\n",
    "    pool_size = trial.suggest_int('pool_size', 2, 4)\n",
    "    dense_units = trial.suggest_int('dense_units', 32, 128)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.5)\n",
    "\n",
    "    # Criação do modelo\n",
    "    model = create_cnn_model(filters=filters,\n",
    "                             kernel_size=kernel_size,\n",
    "                             pool_size=pool_size,\n",
    "                             dense_units=dense_units,\n",
    "                             dropout_rate=dropout_rate)\n",
    "\n",
    "    # Validação cruzada\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        model.fit(X_fold_train, y_fold_train, epochs=10, batch_size=32, verbose=0)\n",
    "        val_loss, val_accuracy = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "        cv_scores.append(val_accuracy)\n",
    "    \n",
    "    # Média da acurácia de validação cruzada\n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "\n",
    "    return mean_cv_accuracy\n",
    "\n",
    "# Estudar otimização com Optuna para CNN\n",
    "study_cnn = optuna.create_study(direction='maximize')\n",
    "study_cnn.optimize(objective_cnn, n_trials=10)\n",
    "\n",
    "# Melhores parâmetros\n",
    "best_params_cnn = study_cnn.best_params\n",
    "print(\"Melhores parâmetros para CNN:\", best_params_cnn)\n",
    "\n",
    "# Treinamento e avaliação do CNN com melhores parâmetros\n",
    "best_cnn_model = create_cnn_model(filters=best_params_cnn['filters'],\n",
    "                                  kernel_size=best_params_cnn['kernel_size'],\n",
    "                                  pool_size=best_params_cnn['pool_size'],\n",
    "                                  dense_units=best_params_cnn['dense_units'],\n",
    "                                  dropout_rate=best_params_cnn['dropout_rate'])\n",
    "\n",
    "# Treinamento do modelo\n",
    "history = best_cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Avaliação da CNN no conjunto de teste\n",
    "cnn_loss, cnn_accuracy = best_cnn_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Predições da CNN no conjunto de teste\n",
    "cnn_predictions = best_cnn_model.predict(X_test)\n",
    "cnn_predictions_classes = np.argmax(cnn_predictions, axis=1)\n",
    "\n",
    "# Classification report da CNN\n",
    "cnn_report = classification_report(y_test, cnn_predictions_classes, target_names=[str(cls) for cls in unique_types], zero_division=1, digits=2)\n",
    "\n",
    "# Matriz de confusão\n",
    "conf_matrix = confusion_matrix(y_test, cnn_predictions_classes)\n",
    "\n",
    "# Acurácia de treinamento\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "# Acurácia da validação cruzada (a média das acurácias obtidas durante a otimização)\n",
    "cv_mean_accuracy = study_cnn.best_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN - Acurácia (Treinamento): 0.9532\n",
      "CNN - Acurácia (Teste): 0.6578\n",
      "Acurácia média na validação cruzada (CNN): 0.9200\n",
      "\n",
      "Matriz de Confusão (CNN):\n",
      "[[78 13  1  5  0]\n",
      " [21 14  1  2  0]\n",
      " [ 2  2 24  1  0]\n",
      " [ 4  2  2  7  0]\n",
      " [ 5  2  0  1  0]]\n",
      "\n",
      "Classification Report (CNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LumA       0.71      0.80      0.75        97\n",
      "        LumB       0.42      0.37      0.39        38\n",
      "       Basal       0.86      0.83      0.84        29\n",
      "        Her2       0.44      0.47      0.45        15\n",
      "      Normal       1.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.66       187\n",
      "   macro avg       0.69      0.49      0.49       187\n",
      "weighted avg       0.66      0.66      0.64       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibindo resultados da CNN\n",
    "print(f'\\nCNN - Acurácia (Treinamento): {train_accuracy:.4f}')\n",
    "print(f'CNN - Acurácia (Teste): {cnn_accuracy:.4f}')\n",
    "print(f'Acurácia média na validação cruzada (CNN): {cv_mean_accuracy:.4f}')\n",
    "print(f'\\nMatriz de Confusão (CNN):\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report (CNN):\\n{cnn_report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
